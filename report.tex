% yay report! if anyone can figure out how to compile latex on here, that would be cool...
\documentclass{article}
\addtolength{\oddsidemargin}{-1in}
\addtolength{\evensidemargin}{-1in}
\addtolength{\textwidth}{2in}
\addtolength{\topmargin}{-.8in}
\addtolength{\textheight}{1.6in}
\title{Information Retrieval Lab 1}
\author{Chiao-ting Fang, Magdalena Parks \&\ Caroline Appleby}
\date{\today}
\begin{document}
\section{Create an inverted index}
The program we implemented is written in Python 3. The inverted index is read in to a Python dictionary, which is implemented under the hood as a hash table. This allows for very fast searching **what order**. In our dictionary, the keys are the individual terms, stored as strings, and the values are Python arrays of integers, where each item in the array is the ID of a document containing this term, conceptually the postings list for that term. Table \ref{table:size} shows the size of our inverted index, with and without lowercasing the input, and with and without removing 10 stop words. % I don't really get **what order** here? it's all based on simple query, and for simple query it's just given the key find value.
\begin{table}[h!]
\centering
\begin{tabular}[|l|l|l|] \hline
Inverted index & Number of terms & Total postings \\ \hline
Original & 4286 & 52788 \\
Original - Stopwords & 4276 & 45100 \\
Lowercased & 3684 & 50966 \\
Lowercased - Stopwords & 3674 & 43163 \\ \hline
\end{tabular}
\caption{\label{table:size}Size of different inverted indexes}
\end{table}


\section{Boolean queries}
% output of query for ``school'', ``school AND kids'', ``really AND kids AND school''
The python functions that we created, though not very effective, are able to find the postings of the given entries. In \texttt{simple\_query} function, the query is the key and the postings are stored as a list in the matching value. Using \textit{school} as the query will return the list \texttt{[72, 111, 223, 224, 268, 385, 431, 494, 532, 553, 554, 564, 581, 582, 996]}, which means the word occurs in text 72, 111, 223, etc. 

\texttt{inter\_queries} is the function that takes two queries, intersects the postings, and returns the document ID for the texts that contain both words. The two queries are extracted using some string methods and the postings for each word are retrieved with \texttt{simple\_query} function mentioned above. The two lists are then turned into sets and using the \texttt{\&} symbol to get the intersection. For \textit{school AND kids}, the intersection of the postings is \texttt{[72, 224, 385, 553]}.

The \textit{inter\_many\_queries} function can handle more than two words and find the postings that have all the queries. To check how many queries there are, a while loop is created and constantly looking for the \texttt{AND} word that separates the queries. The queries are then appended into a list. After figuring out the number of queries, the intersection of the first two words is generated and then the postings of other items are intersected with it one at a time. In the end, the function returns the intersection as a list. For example, queries \textit{really AND kids AND school} occur  in text \texttt{[72, 224, 385]}. 

% return the number of comparisons needed to perform the intersections
The number of comparison steps is not visible for the functions above as most of them used python build-in set methods. In order to see how the comparison works another function \texttt{inter\_queries\_re} is created. This query routine with no optimization works as described in section 1.3 of the textbook **cite**, progressing through two sorted arrays of postings, one for each of the search terms, and appending a document ID to a new list if that ID occurs in both of the existing arrays. This is expected to run in linear time, proportional to the total number of items in the two postings lists. Theoretically the complexity of this algorithm would be \textit{O(x+y)}, \textit{x} and \textit{y} being the length of the two lists respectively. But in practice there may be fewer steps as the length of lists is not always the same. With our function, 30 steps were counted when trying to find the intersection of \textit{school AND kids}. 
% measure the number of comparison steps after adding a query optimization feature
We chose to add the query optimization feature described in section 2.3: the addition of skip pointers to the postings lists. **is this actually going to reduce the time complexity?** This works by adding so-called ``skip pointers'' into the postings lists, which allow us to miss out some comparisons **Chiao-ting can you explain how this works**. In reality, because our postings lists are fairly short, this kind of optimization is not going to make a noticeable difference to the real running time of a query to our inverted index. 

\section{Ranked queries}
% compute inverse document frequencies
Inverted document frequency of a particular term is defined as $\log_10 \frac{N}{df_t}$, where $N$ is the total number of documents in the collection, and $df_t$ is the total number of documents in which that term appears. We can calculate $df_t$ from the length of the postings list of the term in question, since this tells us how many documents the term appears in. The total number of documents in our collection, in this case 1000, is hard-coded into the function definition, as the default value of one of the arguments. 

%make a new file with term frequencies for each document and each term, from lowercased version

% compute TF/IDF for the query  
TF/IDF can be computed directly from the results of calls to the functions for calculating TF and IDF individually, by multiplying these values, according to the definition of TF/IDF as $(1+ \log_10 tf_{t,d})\times \log_10 \frac{N}{df_t}$


% compute cosine similarity measures for the documents you found using TF/IDF

Obviously, if we were to write a real implementation of this to be used in a full-size system, we would not write this by hand, rather use an implementation from one of the many available Python toolkits, for example SciKitLearn or SciPy, since this will be properly optimised and run much more efficiently. 



\end{document}